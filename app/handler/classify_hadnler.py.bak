import numpy as np
import pandas as pd
import tensorflow as tf
from matplotlib import pyplot
from tensorflow.keras import Model
from tensorflow.keras import Sequential
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Input, Dropout, Activation, Dense
from tensorflow.keras.optimizers import Adadelta
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.layers import Dense
from flask import jsonify
import sklearn
from sklearn.preprocessing import MinMaxScaler
import warnings
warnings.filterwarnings('ignore')

def classify():
    filepath = "data/data.csv"
    df = pd.read_csv(filepath)

    vc = df["label"].value_counts()

    df.sort_values(by='ts', inplace=True)
    df['time_diff'] = df['ts'].diff()

    columns_to_drop = ['Unnamed: 0','ts', 'uid', 'id.orig_h', 'local_orig', 'local_resp', 'missed_bytes','history','service'
                    ,'id.orig_p','id.resp_p','service','duration']
    df.drop(columns=columns_to_drop, inplace=True)


    from sklearn.preprocessing import LabelEncoder
    data = {'label': ['PartOfAHorizontalPortScan', 'Okiru', 'Benign',
                    'DDoS', 'C&C', 'C&C-HeartBeat','C&C-FileDownload','Okiru-Attack']}
    labeldata = pd.DataFrame(data)
    label_encoder = LabelEncoder()
    df['label'] = label_encoder.fit_transform(df['label'])
    df['label'] = df['label'].apply(lambda x: 0 if x == label_encoder.transform(['Benign'])[0] else 1)

    columns_to_drop = ['orig_bytes', 'resp_bytes', 'resp_pkts', 'resp_ip_bytes']
    df.drop(columns=columns_to_drop, inplace=True)

    df[df.isnull().any(axis=1)]

    df=df.fillna({'time_diff':'0'})

    proto_mapping = {'tcp': 1, 'udp': 2, 'icmp': 3}  
    conn_state_mapping = {'S0': 1, 'S1': 2, 'S3': 3, 
                        'REJ': 4, 'SF': 5, 'OTH': 6, 'RSTO': 7, 'RSTR': 8} 
    df['proto_encoded'] = df['proto'].map(proto_mapping)
    df['conn_state_encoded'] = df['conn_state'].map(conn_state_mapping)
    df.drop(['proto', 'conn_state'], axis=1, inplace=True)

    df.drop(columns=['id.resp_h'], inplace = True)

    missing_data = df[df['conn_state_encoded'].isnull()]

    from sklearn.preprocessing import MinMaxScaler
    scaler = MinMaxScaler()
    columns_to_normalize = ['orig_pkts', 'orig_ip_bytes', 'time_diff', 'proto_encoded','conn_state_encoded',]
    df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])

    X = df[['orig_pkts', 'orig_ip_bytes', 'time_diff', 'proto_encoded',
        'conn_state_encoded']].values

    Y = df[['label']].values

    df['label'].value_counts()

    import matplotlib.pyplot as plt
    plt.figure()
    label_counts = df['label'].value_counts()
    plt.figure(figsize=(8, 6))
    label_counts.plot(kind='bar', color=['blue', 'red'])  
    plt.title('Distribusi Kelas')
    plt.xlabel('Kelas')
    plt.ylabel('Jumlah')
    plt.xticks([0, 1], ['Benign', 'Malware'])
    plt.savefig('app/static/images/plot.png')

    from sklearn.model_selection import train_test_split
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=10, test_size=0.2)

    model = Sequential()
    model.add(Dense(1000, activation='relu',input_dim=5))
    model.add(Dense(500, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(1, activation='sigmoid'))

    from keras.optimizers import Adam
    learning_rate = 0.001
    optimizer = Adam(learning_rate=learning_rate)
    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])

    from keras.callbacks import EarlyStopping
    from keras.callbacks import ModelCheckpoint
    from keras.models import load_model
    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)
    mc = model.save('best_model1.h5')

    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs = 20, batch_size=512,  verbose=1, callbacks=[es])

    # from tensorflow.keras.models import load_model
    from matplotlib import pyplot
    plt.figure()
    saved_model = load_model('best_model1.h5')
    _, train_acc = saved_model.evaluate(X_train, Y_train, verbose=0)
    _, test_acc = saved_model.evaluate(X_test, Y_test, verbose=0)
    pyplot.plot(history.history['accuracy'], label='train')
    pyplot.plot(history.history['val_accuracy'], label='test')
    pyplot.legend()
    pyplot.savefig('app/static/images/training_history.png')

    plt.figure()
    train_loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(1, len(train_loss) + 1)
    plt.plot(epochs, train_loss, 'bo', label='Training Loss')
    plt.plot(epochs, val_loss, 'r', label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig('app/static/images/training_validation_loss.png')

    Y_pred = model.predict(X_test)
    Y_pred_classes1 = (Y_pred > 0.5).astype(int)    
    from sklearn.metrics import classification_report
    report = classification_report(Y_test, Y_pred_classes1)

    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score
    accuracy = accuracy_score(Y_test, Y_pred_classes1)
    recall = recall_score(Y_test, Y_pred_classes1)
    precision = precision_score(Y_test, Y_pred_classes1)
    f1score = f1_score(Y_test, Y_pred_classes1)

    return jsonify(accuracy, recall, precision, f1score)
